{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest version from GitHub\n",
    "!pip install -q -U git+https://github.com/jdvelasq/techminer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deletion of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\n",
    "    \"https://raw.githubusercontent.com/jdvelasq/techminer/master/data/tutorial/\"\n",
    "    + \"deletion-of-records.json\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting of abstracts of proceedings and workshops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from techminer import Keywords\n",
    "\n",
    "conf = Keywords()\n",
    "conf.add_keywords([\"Conference\", \"Proceeding\", \"Workshop\", \"Congress\"])\n",
    "df[\"CONF\"] = df.Title.map(lambda x: True if x in conf else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th International Conference on Mining Intelligence and Knowledge Exploration, MIKE 2018\n",
      "IEEE Conference on Evolving and Adaptive Intelligent Systems\n",
      "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017\n",
      "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017\n",
      "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017\n",
      "Intelligent Computing in Bioinformatics - 10th International Conference, ICIC 2014, Proceedings\n"
     ]
    }
   ],
   "source": [
    "for title in df[df.CONF][\"Title\"]:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. records before =  152\n",
      "Num. records after =  146\n"
     ]
    }
   ],
   "source": [
    "print(\"Num. records before = \", len(df))\n",
    "\n",
    "df = df[df.CONF.map(lambda x: False if x is True else True)]\n",
    "\n",
    "print(\"Num. records after = \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting of documents with the same title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. records before =  146\n"
     ]
    }
   ],
   "source": [
    "print(\"Num. records before = \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Improving DWT-RNN model via B-spline wavelet m...\n",
      "1    Direct marketing campaigns in retail banking w...\n",
      "2    Combining time-series and textual data for tax...\n",
      "3    Stock price forecasting model based on modifie...\n",
      "4               Sentiment-aware volatility forecasting\n",
      "Name: Title, dtype: object\n",
      "0    a b dwt forecast frequenc high improv model mu...\n",
      "1    and bank campaign deep direct forest in learn ...\n",
      "2    a and approach area combin data deep demand ev...\n",
      "3    analysi and base convolut financi forecast mod...\n",
      "4                      awar forecast sentiment volatil\n",
      "Name: fingerprint, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from techminer.strings import fingerprint\n",
    "\n",
    "df[\"fingerprint\"] = df.Title.map(lambda x: fingerprint(x))\n",
    "\n",
    "#\n",
    "# original title\n",
    "#\n",
    "print(df.Title[0:5])\n",
    "\n",
    "#\n",
    "# Fingerprint of the title\n",
    "#\n",
    "print(df.fingerprint[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"fingerprint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. records after =  145\n"
     ]
    }
   ],
   "source": [
    "print(\"Num. records after = \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### df.to_json(\"keywords-text-clustering.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
