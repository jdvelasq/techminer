{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest version from GitHub\n",
    "# !pip install -q -U git+https://github.com/jdvelasq/techminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from techminer import (\n",
    "    DataFrame,\n",
    "    Plot,\n",
    "    Thesaurus,\n",
    "    extract_country,\n",
    "    heatmap,\n",
    "    text_clustering,\n",
    "    text_nesting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = (\n",
    "    \"https://raw.githubusercontent.com/jdvelasq/techminer/master/data/\"\n",
    "    + \"ieee-latin-america.csv\"\n",
    ")\n",
    "\n",
    "filepath = \"../../data/papers/ieee-latin-america.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3553 entries, 0 to 3552\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Authors                    3553 non-null   object \n",
      " 1   Author(s) ID               3553 non-null   object \n",
      " 2   Title                      3553 non-null   object \n",
      " 3   Year                       3553 non-null   int64  \n",
      " 4   Source title               3553 non-null   object \n",
      " 5   Volume                     3553 non-null   int64  \n",
      " 6   Issue                      3553 non-null   int64  \n",
      " 7   Art. No.                   3067 non-null   float64\n",
      " 8   Page start                 3525 non-null   float64\n",
      " 9   Page end                   3498 non-null   float64\n",
      " 10  Page count                 11 non-null     float64\n",
      " 11  Cited by                   2452 non-null   float64\n",
      " 12  DOI                        3538 non-null   object \n",
      " 13  Link                       3553 non-null   object \n",
      " 14  Affiliations               3509 non-null   object \n",
      " 15  Authors with affiliations  3541 non-null   object \n",
      " 16  Author Keywords            3347 non-null   object \n",
      " 17  Index Keywords             3493 non-null   object \n",
      " 18  Document Type              3553 non-null   object \n",
      " 19  Publication Stage          3553 non-null   object \n",
      " 20  Access Type                55 non-null     object \n",
      " 21  Source                     3553 non-null   object \n",
      " 22  EID                        3553 non-null   object \n",
      "dtypes: float64(5), int64(3), object(15)\n",
      "memory usage: 638.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filepath)\n",
    "df = df.applymap(lambda x: None if pd.isna(x) is True else x)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3553"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Number of records\n",
    "#\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3D modeling;Bottleneck identifications;Computa...\n",
       "1    Combinated Models;Combinatorial Network of Dyn...\n",
       "2    Accident prevention strategies;Critical system...\n",
       "3    Distribution system;Distribution systems;Elect...\n",
       "4    Assistive Technology;Contact surface;Digital s...\n",
       "Name: Keywords, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Keywords merging\n",
    "#\n",
    "df = DataFrame(df).keywords_fusion()\n",
    "df.Keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Number of records without Keywords\n",
    "#\n",
    "len(df[df.Keywords.map(lambda x: x is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Titles of documents without keywords\n",
    "#\n",
    "df[df.Keywords.map(lambda x: x is None)]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Delete of records without keywords\n",
    "#\n",
    "df = df[df.Keywords.map(lambda x: x is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Number of selected records\n",
    "#\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Text clustering of keywords.\n",
    "#   Keyword strings with the same number of words\n",
    "#\n",
    "thesaurus = text_clustering(df.Keywords, sep=\";\", transformer=lambda x: x.lower())\n",
    "with open(\"thesaurus-text-clustering-raw.json\", \"w\") as f:\n",
    "    f.write(thesaurus.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(['abc', 'ab', 'a']).tolist()\n",
    "sorted(x, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Loads the new dictionary\n",
    "#\n",
    "with open(\"thesaurus-text-clustering-cleaned.json\", \"r\") as f:\n",
    "    dictionary = json.loads(f.read())\n",
    "    \n",
    "#\n",
    "#   Loads the new thesaurus\n",
    "#\n",
    "thesaurus = Thesaurus(dictionary, ignore_case=False, full_match=True, use_re=False)\n",
    "\n",
    "#\n",
    "#   Clean the Keywords\n",
    "#\n",
    "thesaurus.compile()\n",
    "df['Keywords'] = df.Keywords.map(lambda x: thesaurus.apply_as_dict(x, sep=\";\"))\n",
    "# thesaurus_dict = thesaurus.to_dict()\n",
    "#Â df['Keywords'] = df.Keywords.map(lambda x: ';'.join([thesaurus_dict[w] if w in thesaurus_dict.keys() else w for w in x.split(';')]))\n",
    "\n",
    "\n",
    "#\n",
    "#   Remove extra blanks between keywords if exists\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: \";\".join(set([w.strip() for w in x.split(\";\")]))\n",
    ")\n",
    "\n",
    "#\n",
    "#   Replace empty strings by None\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(lambda x: x if x != \"\" else None)\n",
    "\n",
    "#\n",
    "#   Number of unique of strings\n",
    "#\n",
    "len(\n",
    "    set([w.strip() for x in df.Keywords if x is not None for w in x.split(\";\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Text nesting\n",
    "#\n",
    "thesaurus = text_nesting(df.Keywords, sep=';', max_distance=1, transformer=lambda x: x.lower())\n",
    "\n",
    "#\n",
    "# Creates a thesaurus with candidate substrings as a thesaurus\n",
    "#\n",
    "with open('thesaurus-text-nesting-raw.json', 'w') as f:\n",
    "    f.write(tn.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Loads the new dictionary\n",
    "#\n",
    "with open(\"thesaurus-text-nesting-cleaned.json\", \"r\") as f:\n",
    "    dictionary = json.loads(f.read())\n",
    "    \n",
    "#\n",
    "#   Loads the new thesaurus\n",
    "#\n",
    "thesaurus = Thesaurus(dictionary, ignore_case=False, full_match=True, use_re=False)\n",
    "\n",
    "#\n",
    "# Apply the thesaurus\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: thesaurus.apply(x, sep=\";\")\n",
    ")\n",
    "\n",
    "#\n",
    "# Remove extra blanks between keywords\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: \";\".join(set([w.strip() for w in x.split(\";\")]))\n",
    ")\n",
    "\n",
    "#\n",
    "# Replace empty strings by None\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: x if x != \"\" else None\n",
    ")\n",
    "\n",
    "#\n",
    "# Number of unique keywords\n",
    "#\n",
    "len(\n",
    "    set(\n",
    "        [w.strip() for x in df.Keywords if x is not None for w in x.split(\";\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A column for identify each record is added to the dataframe.\n",
    "#\n",
    "\n",
    "\n",
    "df = DataFrame(df).generate_ID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Number of terms\n",
    "#\n",
    "df.count_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Author desambiguation\n",
    "#\n",
    "df = DataFrame(df).disambiguate_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most frequent authors\n",
    "#\n",
    "sorted(df.documents_by_term('Authors').head(10).Authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most cited authors\n",
    "#\n",
    "sorted(df.citations_by_term('Authors').head(10).Authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most frequent keywords\n",
    "#\n",
    "df.documents_by_term(\"Keywords\", sep=\";\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most cited keywords\n",
    "#\n",
    "df.citations_by_term(\"Keywords\", sep=\";\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Documents by year\n",
    "#\n",
    "\n",
    "\n",
    "Plot(df.documents_by_year()).bar(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cumulative number of documents by year\n",
    "#\n",
    "Plot(df.documents_by_year(cumulative=True)).barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Worldmap with the number of documents by country\n",
    "#\n",
    "df[\"Country\"] = df[\"Affiliations\"].map(lambda x: extract_country(x, sep=\";\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "Plot(df.documents_by_term(\"Country\", sep=\";\")).worldmap()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
