# get_ipython().getoutput("pip install -q -U git+https://github.com/jdvelasq/techminer")
from techminer.app import App

App().run()





import techminer as tech

tech.correlation_analysis.DASHapp().run()


import ipywidgets as widgets
from ipywidgets import GridspecLayout, Layout

m =widgets.Checkbox(
                value=True,
                description="Article",
                # layout=Layout(width="auto"),  #  , border="2px solid gray"
            )

m


m.style.keys


import techminer as tech

#
# Thematic Analysis
#
tech.thematic_analysis()


import techminer as tech

#
# Descriptive stats
#
tech.descriptive_stats()


import techminer as tech

#
# Top documents report
#
tech.top_documents(top_n=10)





import techminer as tech

#
# Top documents report
#
tech.top_documents(top_n=10)


import techminer as tech

#
# Converts scopus.csv to techminer.csv
#
tech.import_scopus()


import techminer as tech

#
# Creates or modifies the keywords thesaurus.txt
#   Honors previous created file
#
tech.create_keywords_thesaurus()

get_ipython().getoutput("head -n +20 keywords_thesaurus.txt")


import techminer as tech

#
# Keywords cleaning
#
tech.apply_keywords_thesaurus()


METHODS = [
    "anfis",
    "arima",
    "artificial neural network",
    "bayesian networks",
    "deep neural network",
    "exponential smoothing",
    "exponential regression",
    "exponential growth model",
    "extreme learning machine",
    "fuzzy neural networks",
    "gaussian mixture model",
    "genetic algorithm",
    "logistic regression",
    "lasso regression",
    "linear regression",
    "logistic growth model",
    "lstm",
    "neural network autoregressive model",
    "si model",
    "sis model",
    "sir model",
    "sirs model",
    "seir model",
    "si(n)rs model",
    "siz model",
    "stochastic model",
    "support vector machine",
    "time interrupted regression model",
    "maximum entropy method",
    
]

DISEASES = [
    "malaria",
    "covid-19",
    "chickenpox",
    "dengue",
    "ebola",
    "flu",
    "flu epidemics",
    "hepatitis a",
    "herpes zoster",
    "hiv",
    "influenza",
    "malaria",
    "measles",
    "pertussis",
    "pneumovirus",
    "respiratory syncytial virus",
    "rubella",
    "scarlet fever",
    "tuberculosis",
    "varicella",
    "zika fever",
    "vcjd",
]

import pandas as pd
data = pd.read_csv('techminer.csv')

data['DISEASES'] = data['Keywords_CL'].map(lambda w: ';'.join(set([m for m in w.split(';') if m in DISEASES])), na_action='ignore')
data['METHODS'] = data['Keywords_CL'].map(lambda w: ';'.join(set([m for m in w.split(';') if m in METHODS])), na_action='ignore')
data.to_csv("techminer.csv", index=False)
data.METHODS.tail(50)


data.loc[4,:].Keywords_CL


import techminer as tech

#
# Creates a Institutions thesaurus
#
tech.create_institutions_thesaurus()

get_ipython().getoutput("head -n +10 institutions_thesaurus.txt")


import techminer as tech

#
# Institutions cleaning
#
tech.apply_institutions_thesaurus()


import techminer as tech

#
# Coverage
#
tech.coverage()


import pandas as pd
data = pd.read_csv('techminer.csv')
data = data[data.Authors.map(pd.isna)][['Authors', 'Title', 'Year', 'Document_Type']]
data.tail(20)


import techminer as tech

#
# Descriptive stats
#
tech.descriptive_stats()


import techminer as tech

#
# Column explorer
#
tech.column_explorer(top_n=None, only_abstract=True, clusters=None, cluster=None)


import techminer as tech

#
# Matrix explorer
#
tech.matrix_explorer(top_n=100, only_abstract=True, clusters=None, cluster=None)


import techminer as tech

#
# By year analysis
#
tech.by_year_analysis()


import techminer as tech

#
# Top documents report
#
tech.top_documents(top_n=10)


import techminer as tech

#
# By term analysis
#
tech.by_term_analysis(
    limit_to=None, exclude=None, years_range=None
)


import techminer as tech

#
# By-term-per-year
#
tech.by_term_per_year_analysis(tab=0, years_range=None)


import techminer as tech

#
# Growth indicators
#
tech.growth_indicators(exclude=None, years_range=None)


import techminer as tech

#
# Bigraph
#
tech.bigraph_analysis()


import techminer as tech


# TITLE-ABS-KEY
# (
#   ( 
#     "data analytics"  
#     OR  "data science"  
#     OR  "analytics"  
#     OR  "big data"  
#     OR  "machine learning"  
#     OR  "computational intelligence"  
#     OR  "artificial intelligence" 
#   )  
#   AND  
#   ( 
#     ( 
#       energy  OR  power  OR  electricity )  PRE/1  ( market  OR  industry  OR  sector ) ) )  AND  ( LIMIT-TO ( SUBJAREA ,  "ENER" ) ) 
#
tech.apply_keywords_thesaurus()

EXCLUDE = {
    "Author_Keywords_CL":[
        "artificial intelligence",
        "data analytics",
        "big data",
        "machine learning",
        "computacional intelligence",
        "computation intelligence",
        "energy market",
        "energy sector",
        "big data analytics",
        "electricity markets",
        "electric markets",
        "forecast",
        "prediction",
        "simulation",
        "electricity",
        "optimization",
        "energy",
        "optimal power flow",
        
    ],
}

#
# Graph
#
tech.graph_analysis(exclude=None)


import techminer as tech

#
# Correlation
#
tech.correlation_analysis()


import techminer as tech

#
# Bibliometrix conceptual structure
#
tech.conceptual_structure()


import techminer as tech

#
# Co-word analysis
#
tech.co_word_analysis()


import techminer as tech

#
# Associations
#
tech.keywords_association(top_n=50)


import techminer as tech

#
# Comparisons
#
tech.keywords_comparison(top_n=50)


##
## Words to exclude
##


LIMIT_TO = {
    "Author_Keywords_CL": [    
        "adaptive dynamic programming",
        "agent-based modelling",
        "collaborative urban logistics",
        "customer service",
        "decision making",
        "discrete event simulation",
        "e-commerce",
        "game theory",
        "geographic information systems (gis)",
        "green vehicle",
        "greenhouse gas emissions",
        "key performance indicators",
        "last mile delivery",
        "linear programming",
        "location",
        "location routing problem",
        "metaheuristics",
        "mobile depot",
        "multi-criteria decision analysis (mcda)",
        "network logistics",
        "optimization",
        "parcel delivery",
        "parcel locker",
        "performance evaluation",
        "sensitivity analysis",
        "smart cities",
        "social cost benefit analysis",
        "stakeholder analysis",
        "sustainability",
        "sustainable urban freight transport",
        "vehicle routing problem",
    ],
    "Countries":[
        "Italy",
        "China",
        "France",
        "Netherlands",
        "United Kingdom",
        "Belgium",
        "United States",
        "Spain",
        "Australia",
        "Germany",
    ],
    "Authors": [
        "Allen J",
        "Awasthi A",
        "Browne M",
        "Chauhan SS",
        "Dablanc L",
        "Goyal SK",
        "Lebeau P",
        "Leonardi J",
        "Macharis C",
        "Quak HJ",
        "Qureshi AG",
        "Taniguchi E",
        "van Duin R",
        "van Mierlo J",
        "Woodburn A",

    ],
}

LIMIT_TO['Abstract_Author_Keywords_CL'] = LIMIT_TO['Author_Keywords_CL']

EXCLUDE = {
    "Author_Keywords_CL": [
        "business model",
        "case studies",
        "cities",
        "distribution",
        "entropy",
        "freight consolidation",
        "literature review",
        "logistics engineering",
        "logistics sprawl",
        "logistics",
        "micro-consolidation",
        "modelization",
        "policy evaluation",
        "retailer",
        "urban consolidation center",
        "urban freight transport",
        "urban freight",
        "urban logistic",
        "logistic system",
    ]
}


import techminer as tech

#
# Thematic Analysis
#
tech.thematic_analysis()


import techminer as tech

#
# Comparative Analysis
#
tech.comparative_analysis()


import techminer as tech

#
# Latent Semantic Analysis
#
tech.latent_semantic_analysis()








import techminer as tech

#
# Factor Analysis
#
tech.factor_analysis()


import techminer as tech

#
# Document-term
#
tech.document_term_analysis()


##
## Limit to ... / Exclude ...
##
LIMIT_TO = {
    "Author_Keywords": text.find_string(
        patterns="^g",
        x=df.Author_Keywords,
        ignore_case=True,
        full_match=False,
        use_re=True,
    ),
    "Countries": ["United States"],
}

EXCLUDE = {
    "Author_Keywords": text.find_string(
        patterns="^g",
        x=df.Author_Keywords,
        ignore_case=True,
        full_match=False,
        use_re=True,
    ),
    "Countries": ["United States"],
    "Authors": ["Utzinger J", "Polling B"],
}


#
# Clusters
#

CLUSTERS = [
    "Author_Keywords_CL",
    {
        0: [
            "city logistic",
            "urban freight transport",
            "urban freight consolidation center",
            "case studies",
            "stakeholder",
            "game theory",
            "optimization",
            "multi-stakeholder",
        ],
        1: [
            "urban distribution center",
            "sustainability",
            "location selection",
            "distribution center",
            "city logistics centers",
            "multi criteria decision making",
            "location plan",
        ],
        2: [
            "urban consolidation center",
            "business model",
            "last mile delivery",
            "urban distribution",
            "urban freight",
            "freight consolidation",
        ],
        3: [
            "logistics",
            "city distribution center",
            "collaboration",
            "entropy",
            "facility location",
        ],
        4: [
            "urban logistic",
            "freight transport",
            "electric vehicle",
            "cities",
        ],
    },
]


import pandas as pd

data = pd.read_csv("techminer.csv")
for s in data.Abstract_Index_Keywords_CL.dropna():
    print(s)



import pandas as pd

data = pd.read_csv("techminer.csv")
for s in data.Abstract_Author_Keywords_CL.dropna():
    if "city" in s:
        print(s)



import pandas as pd

data = pd.read_csv("techminer.csv")
m = data.Keywords.dropna()
m = m.map(lambda w: w.split(';'))
m = sorted(set(m.explode()))
m


import networkx as nx
nx.__version__


import pandas as pd
pd.DataFrame.from_dict({'A': [0, 1], 'B':[0, 1, 2]})


import pandas as pd
len(['a', 'b'] + [pd.NA] * 2)


m = list('abcdefghi')
m[3] = 0
m


import scipy.spatial
scipy.spatial.ConvexHull
scipy.__version__


import pandas as pd
x = pd.DataFrame({'A': [0, 1], 'B':[3, 4]})
x


x.sum(axis=1)


from nltk import word_tokenize
word_tokenize("Hola mundo-cruel")


'123'.upper()



